# Specify which file storage provider is default
default_file_storage_provider = "minio"

[file_storage_providers.minio]
provider_kind = "s3"
config = { endpoint = "http://localhost:9000", bucket = "erato-storage", region = "us-east-1", access_key_id = "erato-app-user", secret_access_key = "erato-app-password" }
# max_upload_size_kb = 102400  # Optional: Maximum file upload size in KB (100 MB example)

# File processor configuration
# Controls which file processing engine is used to extract text from uploaded documents.
# [file_processor]
# processor = "parser-core"  # Default: "parser-core" - Reliable text extraction for common formats
                             # Alternative: "kreuzberg" - Advanced processor with page-aware markdown extraction
                             # Kreuzberg adds page markers like <page number="1">, <page number="2">, etc.
                             # This is useful for multi-page documents where page references matter.

# Chat providers for e2e tests
[chat_providers]
priority_order = ["test-token-limit"]

# Test model with very low token limit for e2e testing token warnings
# Only accessible to tokentest@example.com user (configured in Keycloak)
[chat_providers.providers.test-token-limit]
provider_kind = "ollama"
model_name = "smollm2:135m"
model_display_name = "Test Model (Low Token Limit)"
# model_name_langfuse = "smollm2-135m"  # Optional: Custom model name for Langfuse reporting (defaults to model_name)
base_url = "http://localhost:12434/v1/"

[chat_providers.providers.test-token-limit.model_capabilities]
context_size_tokens = 1000      # Very low limit for easy testing
cost_input_tokens_per_1m = 0.0
cost_output_tokens_per_1m = 0.0

# Example model settings configuration
# [chat_providers.providers.test-token-limit.model_settings]
# generate_images = false  # Set to true to generate images instead of text (default: false)
# temperature = 0.2        # Optional sampling temperature
# top_p = 0.9              # Optional nucleus sampling parameter
# reasoning_effort = "low" # Optional reasoning effort: "none" | "minimal" | "low" | "medium" | "high"
# verbosity = "medium"     # Optional verbosity: "low" | "medium" | "high"

# Model permissions - allow test model for all users (low token limit makes it test-only anyway)
[model_permissions.rules.allow-test-model-for-all]
rule_type = "allow-all"
chat_provider_ids = ["test-token-limit"]

# Prompt optimizer configuration
# [prompt_optimizer]
# enabled = false
# chat_provider_id = "test-token-limit"
# # prompt can be a string or an object:
# # prompt = "Optional override. If omitted, a default non-interactive prompt-optimizer system prompt is used."
# # prompt = { source = "langfuse", prompt_name = "prompt-optimizer", label = "production", fallback = "Optional fallback" }
# # prompt = { source = "static", prompt = "Explicit static prompt content" }

# From ./run_mcp_server.sh
# [mcp_servers.file_provider]
# transport_type = "sse"
# url = "http://127.0.0.1:63490/sse"

# Example Sentry integration configuration
# [integrations.sentry]
# sentry_dsn = "https://your-sentry-dsn@sentry.io/project-id"

# Example OpenTelemetry integration configuration
# [integrations.otel]
# enabled = true
# endpoint = "http://localhost:4318"
# protocol = "http" # "http" or "grpc"
# service_name = "erato-backend"

# Experimental Sharepoint/OneDrive integration configuration
# Allows users to attach files from their Microsoft OneDrive/Sharepoint to chats.
# Requires the user's access token to have MS Graph API permissions.
# [integrations.experimental_sharepoint]
# enabled = true
# file_upload_enabled = true  # Whether file upload from Sharepoint is enabled (default: true)
# auth_via_access_token = true  # Use the user's access token for MS Graph API (currently required)

# Experimental Entra ID integration configuration
# Exposes organization users and groups to the frontend for sharing features.
# Requires the user's access token to have MS Graph API permissions.
# [integrations.experimental_entra_id]
# enabled = true
# auth_via_access_token = true  # Use the user's access token for MS Graph API (currently required)

# Frontend configuration options for embedded scenarios
# [frontend]
# # Whether to disable file upload functionality in the UI (default: false)
# disable_upload = true
# # Whether to disable automatic focusing of the chat input field (default: false)
# # This prevents unwanted scrolling behavior when navigating to pages with embedded chat
# disable_chat_input_autofocus = true
# # Whether to hide logout functionality from the UI (default: false)
# disable_logout = true
# # Whether to enable message feedback functionality in the UI (default: false)
# # Allows users to submit thumbs up/down ratings with optional comments for messages
# enable_message_feedback = false
# # Whether to enable the comment text field in message feedback (default: false)
# # Requires enable_message_feedback to be true to have any effect
# enable_message_feedback_comments = false
# # Time limit in seconds for editing message feedback after creation (default: unlimited)
# # When set, feedback can only be edited within this time window after creation
# # Example: message_feedback_edit_time_limit_seconds = 300  # 5 minutes
# message_feedback_edit_time_limit_seconds = 300

# Experimental assistants feature configuration
# [experimental_assistants]
# # Whether to enable the experimental assistants feature in the frontend (default: false)
# enabled = false

# Experimental facets feature configuration
# [experimental_facets]
# # Whether only a single facet can be selected at the same time (default: false)
# only_single_facet = false
# # Whether to include the facet display name in the chat box indicator (default: false)
# show_facet_indicator_with_display_name = false
# # List of facet IDs in priority order for display
# priority_order = ["extended_thinking", "web_search"]
# # Global tool allowlist applied regardless of selected facets
# tool_call_allowlist = ["web-search-mcp/*"]
# # Global facet prompt template (optional; empty string disables; default is built-in)
# facet_prompt_template = ""
# # Facets that should be selected by default in the frontend
# default_selected_facets = ["web_search"]
#
# [experimental_facets.facets.extended_thinking]
# display_name = "Extended thinking"
# icon = "iconoir-lightbulb"
# disable_facet_prompt_template = true
# model_settings = { reasoning_effort = "high" }
#
# [experimental_facets.facets.web_search]
# display_name = "Web search"
# icon = "iconoir-globe"
# tool_call_allowlist = ["web-search-mcp/*", "web-access-mcp/*"]
# # additional_system_prompt can be a string or an object:
# # additional_system_prompt = "Please execute one or multiple web searches to answer the user's question."
# # additional_system_prompt = { source = "langfuse", prompt_name = "facet-web-search", label = "production", fallback = "Please execute one or multiple web searches to answer the user's question." }
# # additional_system_prompt = { source = "static", prompt = "Please execute one or multiple web searches to answer the user's question." }
