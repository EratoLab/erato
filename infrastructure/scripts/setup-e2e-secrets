#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.11"
# dependencies = []
# ///

"""Script to setup E2E secrets for test scenarios.

This script reads a secret source file and generates scenario-specific
configuration files for use in the erato-local Helm chart.
"""

import argparse
import sys
import tomllib
from pathlib import Path
from typing import Dict, Any

# Import shared utilities
from k3d_common import VALID_SCENARIOS


def get_config_dir() -> Path:
    """Get the path to the config directory."""
    script_dir = Path(__file__).resolve().parent
    infrastructure_dir = script_dir.parent
    config_dir = infrastructure_dir / "k3d" / "erato-local" / "config"
    return config_dir


def get_secret_source_path() -> Path:
    """Get the path to the secret source file."""
    return get_config_dir() / "e2e-secrets.toml"


def load_secrets() -> Dict[str, Any]:
    """Load secrets from the source file.

    Returns:
        Dictionary containing the secrets

    Raises:
        SystemExit: If file doesn't exist or has invalid syntax
    """
    secret_path = get_secret_source_path()

    if not secret_path.exists():
        print(f"Error: Secret source file not found: {secret_path}", file=sys.stderr)
        print("", file=sys.stderr)
        print("To create the file:", file=sys.stderr)
        print(f"  1. Copy the template: cp {get_config_dir() / 'e2e-secrets.template.toml'} {secret_path}", file=sys.stderr)
        print("  2. Fill in your API keys", file=sys.stderr)
        print("  3. Run: ./scripts/setup-e2e-secrets apply", file=sys.stderr)
        sys.exit(2)

    try:
        with open(secret_path, "rb") as f:
            return tomllib.load(f)
    except tomllib.TOMLDecodeError as e:
        print(f"Error: Invalid TOML syntax in {secret_path}", file=sys.stderr)
        print(f"  {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"Error reading secret file: {e}", file=sys.stderr)
        sys.exit(1)


def validate_secrets(secrets: Dict[str, Any]) -> bool:
    """Validate that required secrets are present and valid.

    Args:
        secrets: Dictionary of secrets to validate

    Returns:
        True if valid, False otherwise
    """
    errors = []

    # Check for required fields
    if "openai_api_key" not in secrets:
        errors.append("Missing required field: openai_api_key")
    elif not secrets["openai_api_key"]:
        errors.append("Field 'openai_api_key' is empty")
    elif secrets["openai_api_key"] in ["<API_KEY>", "<YOUR_API_KEY>", "YOUR_KEY_HERE"]:
        errors.append("Field 'openai_api_key' contains placeholder value - replace with actual API key")
    if "vertex_ai_api_key" not in secrets:
        errors.append("Missing required field: vertex_ai_api_key")
    elif not secrets["vertex_ai_api_key"]:
        errors.append("Field 'vertex_ai_api_key' is empty")
    elif secrets["vertex_ai_api_key"] in ["<API_KEY>", "<YOUR_API_KEY>", "YOUR_KEY_HERE", "<YOUR_VERTEX_AI_API_KEY>"]:
        errors.append("Field 'vertex_ai_api_key' contains placeholder value - replace with actual API key")

    # Print all validation errors
    if errors:
        print("Validation errors:", file=sys.stderr)
        for error in errors:
            print(f"  - {error}", file=sys.stderr)
        return False

    return True


def generate_scenario_config(secrets: Dict[str, Any], scenario: str) -> str:
    """Generate configuration content for a specific scenario.

    Args:
        secrets: Dictionary of secrets
        scenario: Name of the scenario

    Returns:
        TOML configuration string
    """
    if scenario == "many-models":
        providers = [
            {
                "id": "gemini-2-5-flash",
                "model_name": "gemini-2.5-flash",
                "display_name": "Gemini 2.5-flash",
                "provider_kind": "vertex_ai",
                "api_key_secret": "vertex_ai_api_key",
                "region": "europe-west3",
                "supports_reasoning": True,
                "reasoning_effort": "minimal",
            },
            {
                "id": "gemini-2-5-pro",
                "model_name": "gemini-2.5-pro",
                "display_name": "Gemini 2.5-pro",
                "provider_kind": "vertex_ai",
                "api_key_secret": "vertex_ai_api_key",
                "region": "europe-west4",
                "supports_reasoning": True,
                "reasoning_effort": "minimal",
            },
            {
                "id": "gpt-4-1",
                "model_name": "gpt-4.1",
                "display_name": "GPT-4.1",
                "supports_image_understanding": True,
                "provider_kind": "openai",
            },
            {
                "id": "gpt-4-1-mini",
                "model_name": "gpt-4.1-mini",
                "display_name": "GPT-4.1 Mini",
                "supports_image_understanding": True,
                "provider_kind": "openai",
            },
            {
                "id": "gpt-4o-mini",
                "model_name": "gpt-4o-mini",
                "display_name": "GPT-4o Mini",
                "supports_image_understanding": True,
                "provider_kind": "openai",
            },
            {
                "id": "gpt-4-1-no-image",
                "model_name": "gpt-4.1",
                "display_name": "no-image",
                "supports_image_understanding": False,
                "provider_kind": "openai",
            },
            {
                "id": "mock-llm-openai",
                "model_name": "placeholder",
                "display_name": "Mock-LLM",
                "supports_image_understanding": False,
                "provider_kind": "openai",
                "base_url": "http://erato-local-mock-llm-server:44320/base-openai/v1/placeholder",
            },
            {
                "id": "mock-llm-100k",
                "model_name": "placeholder",
                "display_name": "Mock-LLM 100k",
                "supports_image_understanding": False,
                "provider_kind": "openai",
                "base_url": "http://erato-local-mock-llm-server:44320/base-openai/v1/placeholder",
                "context_size_tokens": 100000,
            },
            {
                "id": "mock-llm-200k",
                "model_name": "placeholder",
                "display_name": "Mock-LLM 200k",
                "supports_image_understanding": False,
                "provider_kind": "openai",
                "base_url": "http://erato-local-mock-llm-server:44320/base-openai/v1/placeholder",
                "context_size_tokens": 200000,
            },
        ]
        priority_order = ", ".join([f'"{provider["id"]}"' for provider in providers])
        config_lines = [
            "# Auto-generated E2E secrets configuration",
            f"# Scenario: {scenario}",
            "# DO NOT EDIT THIS FILE MANUALLY - generated by setup-e2e-secrets",
            "",
            "[chat_providers]",
            f"priority_order = [{priority_order}]",
            "",
        ]

        for provider in providers:
            config_lines.extend(
                [
                    f"[chat_providers.providers.{provider['id']}]",
                    f'provider_kind = "{provider["provider_kind"]}"',
                    f'model_name = "{provider["model_name"]}"',
                    f'model_display_name = "{provider["display_name"]}"',
                ]
            )

            if "region" in provider:
                config_lines.append(f'region = "{provider["region"]}"')

            if "base_url" in provider:
                config_lines.append(f'base_url = "{provider["base_url"]}"')
            else:
                secret_key = provider.get("api_key_secret", "openai_api_key")
                config_lines.append(f'api_key = "{secrets[secret_key]}"')

            config_lines.extend(
                [
                    "",
                    f"[chat_providers.providers.{provider['id']}.model_capabilities]",
                ]
            )
            if "supports_image_understanding" in provider:
                config_lines.append(
                    f"supports_image_understanding = {str(provider['supports_image_understanding']).lower()}"
                )
            if "supports_reasoning" in provider:
                config_lines.append(
                    f"supports_reasoning = {str(provider['supports_reasoning']).lower()}"
                )
            if "context_size_tokens" in provider:
                config_lines.append(
                    f"context_size_tokens = {provider['context_size_tokens']}"
                )
            config_lines.append("")

            if "reasoning_effort" in provider:
                config_lines.extend(
                    [
                        f"[chat_providers.providers.{provider['id']}.model_settings]",
                        f'reasoning_effort = "{provider["reasoning_effort"]}"',
                        "",
                    ]
                )

        config_lines.extend(
            [
                "[mcp_servers_global]",
                "max_session_idle_seconds = 3600",
                "",
                "[mcp_servers.mock_mcp_progress]",
                'transport_type = "streamable_http"',
                'url = "http://erato-local-mock-mcp-server:44321/mcp/progress"',
                "",
                "[frontend.additional_environment]",
                f'K3D_TEST_SCENARIO = "{scenario}"',
                "",
            ]
        )
        return "\n".join(config_lines)

    # Build the configuration content
    config_lines = [
        "# Auto-generated E2E secrets configuration",
        f"# Scenario: {scenario}",
        "# DO NOT EDIT THIS FILE MANUALLY - generated by setup-e2e-secrets",
        "",
        "[chat_providers]",
        'priority_order = ["main"]',
        "",
        "[chat_providers.providers.main]",
        'provider_kind = "openai"',
        'model_name = "gpt-4o-mini"',
        f'api_key = "{secrets["openai_api_key"]}"',
        "",
        "[chat_providers.providers.main.model_capabilities]",
        "supports_image_understanding = true",
        "",
    ]

    # Add optional Anthropic API key if present
    if "anthropic_api_key" in secrets and secrets["anthropic_api_key"]:
        config_lines.extend([
            "# Anthropic provider (if needed)",
            "# [chat_providers.providers.anthropic]",
            "# provider_kind = \"anthropic\"",
            "# model_name = \"claude-3-5-sonnet-20241022\"",
            f"# api_key = \"{secrets['anthropic_api_key']}\"",
            "",
        ])

    # Add frontend environment variables
    config_lines.append("[frontend.additional_environment]")
    config_lines.append(f'K3D_TEST_SCENARIO = "{scenario}"')

    # Scenario-specific data object
    if scenario == "entra_id":
        # Build scenario_data object with Entra ID test user credentials
        scenario_data = {}
        if "entraid_user1_email" in secrets and secrets["entraid_user1_email"]:
            scenario_data["entraid_user1_email"] = secrets["entraid_user1_email"]
        if "entraid_user1_password" in secrets and secrets["entraid_user1_password"]:
            scenario_data["entraid_user1_password"] = secrets["entraid_user1_password"]
        if "entraid_user2_email" in secrets and secrets["entraid_user2_email"]:
            scenario_data["entraid_user2_email"] = secrets["entraid_user2_email"]
        if "entraid_user2_password" in secrets and secrets["entraid_user2_password"]:
            scenario_data["entraid_user2_password"] = secrets["entraid_user2_password"]

        # Add as inline table (TOML format)
        if scenario_data:
            import json
            # Convert to JSON for inline TOML representation
            scenario_data_items = [f'{k} = "{v}"' for k, v in scenario_data.items()]
            config_lines.append(f'SCENARIO_DATA = {{ {", ".join(scenario_data_items)} }}')

    config_lines.append("")
    return "\n".join(config_lines)


def cmd_check(args: argparse.Namespace) -> int:
    """Check if E2E secrets are properly configured.

    Returns:
        0 if valid, non-zero otherwise
    """
    print("Checking E2E secrets configuration...")

    # Load secrets
    try:
        secrets = load_secrets()
    except SystemExit as e:
        return e.code

    # Validate secrets
    if not validate_secrets(secrets):
        return 1

    # Check if output files exist
    config_dir = get_config_dir()
    missing_files = []
    for scenario in VALID_SCENARIOS:
        output_file = config_dir / f"erato.scenario-{scenario}.auto.toml"
        if not output_file.exists():
            missing_files.append(output_file.name)

    if missing_files:
        print(f"Warning: Generated files missing: {', '.join(missing_files)}", file=sys.stderr)
        print("Run: ./scripts/setup-e2e-secrets apply", file=sys.stderr)
        return 1

    print("✓ E2E secrets are properly configured")
    return 0


def cmd_apply(args: argparse.Namespace) -> int:
    """Apply E2E secrets by generating scenario-specific config files.

    Returns:
        0 if successful, non-zero otherwise
    """
    print("Applying E2E secrets configuration...")

    # Load secrets
    try:
        secrets = load_secrets()
    except SystemExit as e:
        return e.code

    # Validate secrets
    if not validate_secrets(secrets):
        return 1

    # Generate config files for each scenario
    config_dir = get_config_dir()
    generated_files = []

    for scenario in VALID_SCENARIOS:
        output_file = config_dir / f"erato.scenario-{scenario}.auto.toml"

        try:
            config_content = generate_scenario_config(secrets, scenario)
            output_file.write_text(config_content)
            generated_files.append(output_file.name)
            print(f"  ✓ Generated {output_file.name}")
        except Exception as e:
            print(f"Error writing {output_file}: {e}", file=sys.stderr)
            return 1

    print()
    print(f"Successfully generated {len(generated_files)} scenario configuration files")
    return 0


def main():
    parser = argparse.ArgumentParser(
        description="Setup E2E secrets for test scenarios",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=f"""
Commands:
  check   Validate that secrets are properly configured
  apply   Generate scenario-specific configuration files from secrets

Secret source file: {get_secret_source_path()}

Available scenarios: {', '.join(VALID_SCENARIOS)}
        """
    )

    subparsers = parser.add_subparsers(dest="command", help="Command to execute")
    subparsers.required = True

    # check command
    parser_check = subparsers.add_parser(
        "check",
        help="Validate E2E secrets configuration"
    )
    parser_check.set_defaults(func=cmd_check)

    # apply command
    parser_apply = subparsers.add_parser(
        "apply",
        help="Generate scenario configs from secrets"
    )
    parser_apply.set_defaults(func=cmd_apply)

    args = parser.parse_args()

    # Execute the command
    exit_code = args.func(args)
    sys.exit(exit_code)


if __name__ == "__main__":
    main()
