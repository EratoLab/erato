# Infrastructure overview

This page provides an overview of the core architecture and infrastructure components that make up the Erato platform. Understanding these components is essential for successfully deploying and operating Erato in your environment.

Erato's architecture is designed with **extensibility** at its core - particularly through the Model Context Protocol (MCP) servers - enabling you to integrate external data sources, APIs, and tools to meet your organization's specific needs.

The modular design also has significant **operational impact**: the number of running services is kept intentionally small for simpler operation and maintenance, while still allowing you to scale individual components independently and adapt the deployment to your infrastructure requirements.
Some parts (e.g. file processor) also have to option to involve external services as part of their processign steps in order to make them more extensible.

For detailed deployment instructions using Helm, see the [Helm deployment guide](./deployment_helm).

## Architecture Diagram (simplified)

The following diagram illustrates the simplified architecture of an Erato deployment:

```mermaid
graph LR
    User[User]
    AuthProxy[Authorization Proxy<br/>oauth2-proxy]
    Erato[Erato App<br/>Backend + Frontend]
    DB[(PostgreSQL<br/>Database)]

    subgraph MCPGroup[MCP Servers]
        direction TB
        MCP1[MCP Server 1]
        MCP2[MCP Server 2]
        MCPn[MCP Server N]
        MCP1 ~~~ MCP2
        MCP2 ~~~ MCPn
    end

    User --> AuthProxy
    AuthProxy --> Erato
    Erato --> MCPGroup
    Erato --> DB

    style User fill:none,stroke:#3b82f6,stroke-width:3px
    style AuthProxy fill:none,stroke:#f59e0b,stroke-width:3px
    style Erato fill:none,stroke:#10b981,stroke-width:3px
    style DB fill:none,stroke:#ef4444,stroke-width:3px
    style MCPGroup fill:none,stroke:#a855f7,stroke-width:3px,stroke-dasharray: 5 5
    style MCP1 fill:none,stroke:#a855f7,stroke-width:2px
    style MCP2 fill:none,stroke:#a855f7,stroke-width:2px
    style MCPn fill:none,stroke:#a855f7,stroke-width:2px
```

**Flow description:**

1. **User** accesses the application through their browser
2. **Authorization Proxy** ([oauth2-proxy](./oauth2_proxy)) handles authentication and validates user sessions via OIDC
3. **Erato App** serves the frontend and provides the backend API
4. **PostgreSQL Database** stores all persistent data (conversations, documents, user settings, etc.)
5. **MCP Servers** provide external integrations and tool capabilities (can be multiple instances for different services)

## Extended Architecture (Example)

The following diagram shows a more concrete example of an Erato deployment with specific MCP servers and external integrations:

```mermaid
graph LR
    User[User]

    subgraph AuthLayer[ ]
        direction TB
        EntraID[Microsoft<br/>Entra ID]
        AuthProxy[Authorization Proxy<br/>oauth2-proxy]
        EntraID ~~~ AuthProxy
    end

    Erato[Erato App<br/>Backend + Frontend]
    DB[(PostgreSQL<br/>Database)]

    subgraph MCPServers[MCP Servers]
        direction TB

        subgraph MCPBuiltin[Built-in MCP Servers]
            direction TB
            WebAccess[Web Access<br/>MCP Server]
            WebSearch[Web Search<br/>MCP Server]
            WebAccess ~~~ WebSearch
        end

        subgraph MCPCustom[Custom MCP Servers]
            direction TB
            IntranetMCP[Intranet<br/>MCP Server]
        end

        subgraph MCPExternal[External MCP Servers]
            direction TB
            JiraMCP[JIRA<br/>MCP Server]
        end

        MCPBuiltin ~~~ MCPCustom
        MCPCustom ~~~ MCPExternal
    end

    Intranet[Internal Intranet<br/>Service]
    JiraSaaS[JIRA<br/>SaaS Service]

    User --> AuthLayer
    AuthProxy --> Erato
    EntraID -.-> AuthProxy
    Erato -.-> EntraID
    Erato --> DB
    Erato -->|auth: none/simple| WebAccess
    Erato -->|auth: none/simple| WebSearch
    Erato -->|auth: forwarded| IntranetMCP
    Erato -->|auth: oauth2| JiraMCP
    IntranetMCP --> Intranet
    JiraMCP --> JiraSaaS

    style User fill:none,stroke:#3b82f6,stroke-width:3px
    style AuthLayer fill:none,stroke:none
    style AuthProxy fill:none,stroke:#f59e0b,stroke-width:3px
    style EntraID fill:none,stroke:#06b6d4,stroke-width:3px
    style Erato fill:none,stroke:#10b981,stroke-width:3px
    style DB fill:none,stroke:#ef4444,stroke-width:3px
    style MCPServers fill:none,stroke:none
    style MCPBuiltin fill:none,stroke:#8b5cf6,stroke-width:3px,stroke-dasharray: 5 5
    style MCPCustom fill:none,stroke:#a855f7,stroke-width:3px,stroke-dasharray: 5 5
    style MCPExternal fill:none,stroke:#ec4899,stroke-width:3px,stroke-dasharray: 5 5
    style WebAccess fill:none,stroke:#8b5cf6,stroke-width:2px
    style WebSearch fill:none,stroke:#8b5cf6,stroke-width:2px
    style IntranetMCP fill:none,stroke:#a855f7,stroke-width:2px
    style JiraMCP fill:none,stroke:#ec4899,stroke-width:2px
    style Intranet fill:none,stroke:#64748b,stroke-width:3px
    style JiraSaaS fill:none,stroke:#64748b,stroke-width:3px
```

**Key components in this example:**

1. **Microsoft Entra ID** provides identity and authentication services:

   - The authorization proxy uses it for OIDC authentication
   - The Erato application reads user and group information from the identity provider for access control and user management

2. **Built-in MCP Servers** (Web Access, Web Search) are deployed as part of the Erato installation and provide web browsing capabilities:

   - **Authentication**: `none/simple` - These servers require no authentication or simple API keys, as they don't access sensitive organizational data

3. **Custom MCP Servers** extend functionality with organization-specific integrations:

   - **Intranet MCP Server** connects to internal company intranet services
   - **Authentication**: `forwarded` - User authentication credentials are forwarded from Erato to the MCP server, allowing it to access the intranet service on behalf of the authenticated user

4. **External MCP Servers** are provided by external SaaS vendors:

   - **JIRA MCP Server** integrates with external SaaS JIRA instance for project management
   - **Authentication**: `oauth2` - The MCP server uses OAuth2 to authenticate with the JIRA service, typically using service account credentials or user-delegated tokens

5. External services (Intranet, JIRA) are accessed through their respective MCP servers, maintaining a clean separation of concerns and proper authentication boundaries

## Message Lifecycle

This section explains how Erato processes chat messages from submission through LLM generation and final persistence.

### High-Level Overview

The message lifecycle consists of five main phases:

```mermaid
sequenceDiagram
    participant ğŸŒ Frontend
    participant ğŸ–¥ï¸ Backend API
    participant ğŸ’¾ PostgreSQL
    participant ğŸ“Š Langfuse
    participant ğŸ¤– LLM Provider
    participant ğŸ”§ MCP Servers

    rect rgba(59, 130, 246, 0.15)
    Note over ğŸŒ Frontend,ğŸ’¾ PostgreSQL: 1. Submission & Persistence
    end
    ğŸŒ Frontend->>ğŸ–¥ï¸ Backend API: Submit message (SSE)
    ğŸ–¥ï¸ Backend API->>ğŸ’¾ PostgreSQL: Save user message
    ğŸ–¥ï¸ Backend API->>ğŸŒ Frontend: SSE: UserMessageCreated

    rect rgba(16, 185, 129, 0.15)
    Note over ğŸ–¥ï¸ Backend API,ğŸ’¾ PostgreSQL: 2. File Processing & Composition
    end
    ğŸ–¥ï¸ Backend API->>ğŸ–¥ï¸ Backend API: Process uploaded files
    ğŸ–¥ï¸ Backend API->>ğŸ’¾ PostgreSQL: Retrieve message history
    ğŸ–¥ï¸ Backend API->>ğŸ–¥ï¸ Backend API: Compose generation input

    rect rgba(245, 158, 11, 0.15)
    Note over ğŸ–¥ï¸ Backend API,ğŸ“Š Langfuse: 3. Tracing Setup (if enabled)
    end
    ğŸ–¥ï¸ Backend API->>ğŸ“Š Langfuse: Create trace
    ğŸ–¥ï¸ Backend API->>ğŸ”§ MCP Servers: List available tools

    rect rgba(168, 85, 247, 0.15)
    Note over ğŸ–¥ï¸ Backend API,ğŸ”§ MCP Servers: 4. Turn Lifecycle Loop
    end
    loop Until final message generated
        ğŸ–¥ï¸ Backend API->>ğŸ”§ MCP Servers: Execute pending tool calls
        ğŸ–¥ï¸ Backend API->>ğŸ¤– LLM Provider: Stream chat completion
        ğŸ¤– LLM Provider-->>ğŸ–¥ï¸ Backend API: Response + tool calls
        ğŸ–¥ï¸ Backend API->>ğŸŒ Frontend: SSE: Text deltas & tool updates
    end

    rect rgba(236, 72, 153, 0.15)
    Note over ğŸ–¥ï¸ Backend API,ğŸ’¾ PostgreSQL: 5. Finalization
    end
    ğŸ–¥ï¸ Backend API->>ğŸ’¾ PostgreSQL: Save assistant message
    ğŸ–¥ï¸ Backend API->>ğŸ“Š Langfuse: Update trace output
    ğŸ–¥ï¸ Backend API->>ğŸŒ Frontend: SSE: MessageComplete
```

### Phase 1: Submission & Persistence

The request arrives via SSE endpoint and the user message is immediately persisted:

```mermaid
sequenceDiagram
    participant ğŸŒ Frontend
    participant ğŸ–¥ï¸ Backend API
    participant ğŸ’¾ PostgreSQL

    ğŸŒ Frontend->>ğŸ–¥ï¸ Backend API: Submit message (SSE)<br/>- user_message<br/>- input_files_ids<br/>- previous_message_id (optional)<br/>- chat_id (optional)

    ğŸ–¥ï¸ Backend API->>ğŸ’¾ PostgreSQL: Get or create chat
    ğŸ’¾ PostgreSQL-->>ğŸ–¥ï¸ Backend API: Chat record

    ğŸ–¥ï¸ Backend API->>ğŸ’¾ PostgreSQL: Save user message<br/>- Message content (JSON)<br/>- Chat association<br/>- Previous message link<br/>- Attached file references
    ğŸ’¾ PostgreSQL-->>ğŸ–¥ï¸ Backend API: message_id

    ğŸ–¥ï¸ Backend API->>ğŸŒ Frontend: SSE: UserMessageCreated<br/>- message_id<br/>- chat_id
```

**Key operations:**

- Chat is created if it doesn't exist
- User message is immediately saved to ensure it's not lost
- Frontend receives confirmation via SSE event

### Phase 2: File Processing & Message Composition

Files are processed and the complete LLM input is assembled from multiple sources:

```mermaid
sequenceDiagram
    participant ğŸ–¥ï¸ Backend API
    participant ğŸ’¾ PostgreSQL
    participant ğŸ“¦ File Storage
    participant ğŸ“Š Langfuse

    Note over ğŸ–¥ï¸ Backend API: File Processing (parallel)
    loop For each input file
        ğŸ–¥ï¸ Backend API->>ğŸ“¦ File Storage: Fetch file contents
        ğŸ“¦ File Storage-->>ğŸ–¥ï¸ Backend API: Raw file data
        ğŸ–¥ï¸ Backend API->>ğŸ–¥ï¸ Backend API: Extract text (PDF, DOCX, etc.)<br/>Cache result
    end

    Note over ğŸ–¥ï¸ Backend API,ğŸ’¾ PostgreSQL: Message History Retrieval
    ğŸ–¥ï¸ Backend API->>ğŸ’¾ PostgreSQL: Retrieve messages<br/>for this chat
    ğŸ’¾ PostgreSQL-->>ğŸ–¥ï¸ Backend API: Historical messages (JSON)

    Note over ğŸ–¥ï¸ Backend API,ğŸ“Š Langfuse: System Prompt Retrieval (optional)
    opt Langfuse prompt management enabled
        ğŸ–¥ï¸ Backend API->>ğŸ“Š Langfuse: Retrieve system prompt<br/>for chat provider
        ğŸ“Š Langfuse-->>ğŸ–¥ï¸ Backend API: System prompt text
    end

    Note over ğŸ–¥ï¸ Backend API: Composition
    ğŸ–¥ï¸ Backend API->>ğŸ–¥ï¸ Backend API: Build generation input:<br/>1. System prompt (global)<br/>2. Assistant prompt (if configured)<br/>3. Message history (parsed)<br/>4. File contents (as text/images)<br/>5. Current user message
```

**Key operations:**

- Files are processed in parallel with caching for performance
- Message history is retrieved
- Generation input is composed in specific order: system prompt â†’ assistant prompt â†’ history â†’ files â†’ current message

### Phase 3: Turn Lifecycle Loop

The core generation loop handles multi-turn interactions with tool calls:

```mermaid
sequenceDiagram
    participant ğŸŒ Frontend
    participant ğŸ–¥ï¸ Backend API
    participant ğŸ“Š Langfuse
    participant ğŸ¤– LLM Provider
    participant ğŸ”§ MCP Servers

    Note over ğŸ–¥ï¸ Backend API: Turn Loop (max 15 iterations)
    loop For each turn (turn_number++)

        alt Turn > 1: Process pending tool calls
            loop For each pending tool call
                ğŸ–¥ï¸ Backend API->>ğŸŒ Frontend: SSE: ToolCallProposed
                ğŸ–¥ï¸ Backend API->>ğŸ”§ MCP Servers: call_tool(server_id, name, args)
                ğŸ”§ MCP Servers-->>ğŸ–¥ï¸ Backend API: Tool result (JSON/text)
                ğŸ–¥ï¸ Backend API->>ğŸŒ Frontend: SSE: ToolCallUpdate (status: success)
                ğŸ–¥ï¸ Backend API->>ğŸ“Š Langfuse: Record tool call span
                ğŸ–¥ï¸ Backend API->>ğŸ–¥ï¸ Backend API: Append tool result to messages
            end
        end

        Note over ğŸ–¥ï¸ Backend API,ğŸ¤– LLM Provider: LLM Generation
        ğŸ–¥ï¸ Backend API->>ğŸ“Š Langfuse: Start generation span
        ğŸ–¥ï¸ Backend API->>ğŸ¤– LLM Provider: Request chat completion (streaming)<br/>- messages (with tool results)<br/>- tools (MCP tool definitions)

        loop Stream response
            ğŸ¤– LLM Provider-->>ğŸ–¥ï¸ Backend API: Chunk: text delta
            ğŸ–¥ï¸ Backend API->>ğŸŒ Frontend: SSE: MessageTextDelta
        end

        ğŸ¤– LLM Provider-->>ğŸ–¥ï¸ Backend API: StreamEnd:<br/>- finish_reason<br/>- tool_calls (if any)<br/>- usage (tokens)

        ğŸ–¥ï¸ Backend API->>ğŸ“Š Langfuse: Finish generation span<br/>- input tokens<br/>- output tokens<br/>- model<br/>- latency

        alt finish_reason == "tool_calls"
            ğŸ–¥ï¸ Backend API->>ğŸ–¥ï¸ Backend API: Add tool calls to pending queue
            Note over ğŸ–¥ï¸ Backend API: Continue to next turn
        else finish_reason == "stop"
            Note over ğŸ–¥ï¸ Backend API: Exit loop - generation complete
        end
    end
```

**Key operations:**

- Each turn starts by executing any pending tool calls from the previous turn
- Tool calls are executed via MCP servers with real-time SSE updates
- LLM generation is streamed with text deltas sent to frontend
- If LLM requests more tool calls, loop continues (up to 15 turns)
- Langfuse tracks each turn separately with detailed metrics

### Phase 4: Finalization

The complete assistant message is saved with all metadata:

```mermaid
sequenceDiagram
    participant ğŸŒ Frontend
    participant ğŸ–¥ï¸ Backend API
    participant ğŸ’¾ PostgreSQL
    participant ğŸ“Š Langfuse

    Note over ğŸ–¥ï¸ Backend API: Assemble final message
    ğŸ–¥ï¸ Backend API->>ğŸ–¥ï¸ Backend API: Build message JSON:<br/>- role: "assistant"<br/>- content: [text, tool_uses]<br/>- generation_metadata

    ğŸ–¥ï¸ Backend API->>ğŸ’¾ PostgreSQL: Save assistant message<br/>- Message content (JSON)<br/>- Generation input context<br/>- Generation parameters<br/>- Metadata (model, tokens, tools, turns)
    ğŸ’¾ PostgreSQL-->>ğŸ–¥ï¸ Backend API: assistant_message_id

    ğŸ–¥ï¸ Backend API->>ğŸ“Š Langfuse: Update trace<br/>- output (final message)<br/>- metadata (cumulative stats)

    ğŸ–¥ï¸ Backend API->>ğŸŒ Frontend: SSE: MessageComplete<br/>- message_id<br/>- total_tokens<br/>- turn_count
```

**Key operations:**

- Assistant message is constructed with all text content and tool uses
- Complete message is saved with generation metadata (model, tokens, turns)
- Langfuse trace is updated with final output
- Frontend receives completion event

### Langfuse Integration

When enabled, Langfuse provides observability throughout the lifecycle:

**Trace Creation:**

- Trace ID created at start of request
- Associated with user_id and session_id (chat_id)

**Generation Spans:**

- One span per turn
- Captures input messages, output, token counts, and latency
- Includes model and provider information

**Tool Call Tracking:**

- Each tool call recorded as metadata
- Tool names aggregated for trace-level statistics

**Final Metrics:**

- Cumulative token usage across all turns
- Total turn count
- Complete request duration

## Stream Buffering & Reconnection

Erato implements a robust streaming infrastructure that allows clients to reconnect to ongoing message generations without losing any events. This is particularly important for handling network interruptions or browser tab refreshes.

### Architecture Overview

```mermaid
sequenceDiagram
    participant ğŸŒ Client 1
    participant ğŸŒ Client 2
    participant ğŸ–¥ï¸ Backend API
    participant ğŸ“¦ Streaming Buffer
    participant ğŸ¤– Generation Task

    Note over ğŸ–¥ï¸ Backend API,ğŸ“¦ Streaming Buffer: Initial Connection
    ğŸŒ Client 1->>ğŸ–¥ï¸ Backend API: POST /me/messages/submit (SSE)
    ğŸ–¥ï¸ Backend API->>ğŸ“¦ Streaming Buffer: Create StreamingTask<br/>- Broadcast channel<br/>- Event history
    ğŸ–¥ï¸ Backend API->>ğŸ¤– Generation Task: Start background generation
    ğŸ–¥ï¸ Backend API->>ğŸŒ Client 1: Subscribe to live events

    loop Generation in progress
        ğŸ¤– Generation Task->>ğŸ“¦ Streaming Buffer: Send event
        ğŸ“¦ Streaming Buffer->>ğŸ“¦ Streaming Buffer: 1. Store in history<br/>2. Broadcast to subscribers
        ğŸ“¦ Streaming Buffer->>ğŸŒ Client 1: SSE event
    end

    Note over ğŸŒ Client 1: Connection drops

    Note over ğŸ–¥ï¸ Backend API,ğŸ“¦ Streaming Buffer: Reconnection
    ğŸŒ Client 2->>ğŸ–¥ï¸ Backend API: POST /me/messages/resumestream<br/>- chat_id
    ğŸ–¥ï¸ Backend API->>ğŸ“¦ Streaming Buffer: Get task by chat_id
    ğŸ“¦ Streaming Buffer-->>ğŸ–¥ï¸ Backend API: StreamingTask
    ğŸ–¥ï¸ Backend API->>ğŸ“¦ Streaming Buffer: Get event history
    ğŸ“¦ Streaming Buffer-->>ğŸ–¥ï¸ Backend API: All previous events

    Note over ğŸ–¥ï¸ Backend API,ğŸŒ Client 2: Replay + Live Stream
    loop Replay history
        ğŸ–¥ï¸ Backend API->>ğŸŒ Client 2: Historical event
    end

    ğŸ–¥ï¸ Backend API->>ğŸŒ Client 2: Subscribe to live events

    loop Ongoing generation
        ğŸ¤– Generation Task->>ğŸ“¦ Streaming Buffer: Send new event
        ğŸ“¦ Streaming Buffer->>ğŸŒ Client 2: SSE event (live)
    end
```

### How It Works

**1. Streaming Buffer Creation**

When a message submission starts, the backend creates a `StreamingTask` associated with the chat ID:

- **Broadcast Channel**: Uses Tokio's broadcast channel with 1,000 event capacity for live streaming
- **Event History**: Stores up to 10,000 events in memory for replay capability
- **Task Lifecycle**: Managed per-chat, allowing only one active generation per chat

**2. Event Flow**

Every event generated during message processing follows this flow:

1. Event is sent to the `StreamingTask`
2. Event is stored in the history buffer (if under 10,000 events)
3. Event is broadcast to all currently subscribed clients via the broadcast channel
4. If no clients are subscribed, the event is still stored in history

**3. Reconnection Process**

Clients can reconnect to an ongoing generation using the `/me/messages/resumestream` endpoint:

```
POST /api/v1beta/me/messages/resumestream
{
  "chat_id": "uuid-of-chat"
}
```

The reconnection process:

1. **Verify Access**: Checks that the user has permission to access the chat
2. **Retrieve Task**: Looks up the active `StreamingTask` for the chat_id
3. **Get History**: Retrieves all events stored in the event history
4. **Replay Events**: Streams all historical events to the client first
5. **Subscribe to Live**: After replay, subscribes to live events
6. **Seamless Transition**: Client receives complete event stream without gaps

This architecture allows us to do generation over long-running tasks that are resilient to network connection issues or
user behaviour that may terminate a generation task (e.g. closing a browser tab with ongoing generation)
